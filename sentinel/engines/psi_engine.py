"""
Stock Sentinel â€” Pre-signal Index Engine
3ìš”ì†Œ ì ìˆ˜ ê³„ì‚° â†’ ì¢…í•© PSI ì‚°ì¶œ â†’ ë“±ê¸‰ íŒì •
"""
import json
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional

import sys, os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), ".."))
from config.settings import (
    SCORE_WEIGHTS, CONFLUENCE_BONUS, NOISE_PENALTY_MAX,
    PSI_LEVELS, TRIGGER_PSI_THRESHOLD,
    OPTIONS_SCORING, ATTENTION_SCORING, FACT_SCORING,
    BREAKING_KEYWORDS, POSITIVE_KEYWORDS, NEGATIVE_KEYWORDS,
    WATCHMAP,
)
from storage.database import (
    save_psi_score, get_recent_news, get_recent_social,
    get_latest_psi, get_psi_history,
)


class PreSignalEngine:
    """Pre-signal Index ê³„ì‚° ì—”ì§„"""
    
    def __init__(self, ticker: str):
        self.ticker = ticker
        self.watch = WATCHMAP.get(ticker)
        self.details = {}  # ì ìˆ˜ ì‚°ì¶œ ìƒì„¸ ê·¼ê±°
    
    def calculate(self, 
                  options_data: Dict = None,
                  social_data: Dict = None,
                  news_data: List[Dict] = None,
                  price_data: Dict = None) -> Dict:
        """
        ì „ì²´ Pre-signal Index ê³„ì‚°
        
        Returns:
            {
                "ticker": str,
                "options_score": float,
                "attention_score": float,
                "fact_score": float,
                "confluence_bonus": float,
                "noise_penalty": float,
                "psi_total": float,
                "level": str,
                "details": dict,
            }
        """
        # 1. ê° ìš”ì†Œ ì ìˆ˜ ê³„ì‚°
        opt_score, opt_details = self._calc_options_score(options_data or {})
        att_score, att_details = self._calc_attention_score(social_data or {}, news_data or [])
        fact_score, fact_details = self._calc_fact_score(news_data or [])
        
        # 1b. ê°€ê²© ì¶©ê²© ë³´ë„ˆìŠ¤ (ê¸‰ë“±/ê¸‰ë½ ì‹œ PSI ì§ì ‘ ë¶€ìŠ¤íŠ¸)
        price_boost, price_boost_details = self._calc_price_boost(price_data or {})
        
        # 2. Confluence ë³´ë„ˆìŠ¤ (2ê°œ ì´ìƒ ìš”ì†Œê°€ ë™ì‹œì— ë†’ì„ ë•Œ)
        high_count = sum(1 for s in [opt_score, att_score, fact_score] if s >= 5)
        confluence = CONFLUENCE_BONUS if high_count >= 2 else 0
        
        # 3. Noise íŒ¨ë„í‹° (í‰ì‹œ ë…¸ì´ì¦ˆ ìˆ˜ì¤€ ë³´ì •)
        noise = self._calc_noise_penalty(att_score, fact_score)
        
        # 4. ì¢…í•© ì ìˆ˜ (ê°€ê²© ì¶©ê²©ì€ ì§ì ‘ ê°€ì‚°)
        psi = (
            SCORE_WEIGHTS["options"] * opt_score +
            SCORE_WEIGHTS["attention"] * att_score +
            SCORE_WEIGHTS["fact"] * fact_score +
            confluence + price_boost - noise
        )
        psi = max(0, min(10, round(psi, 1)))
        
        # 5. ë“±ê¸‰ íŒì •
        level = self._get_level(psi)
        
        # 6. ìƒì„¸ ê·¼ê±°
        self.details = {
            "options": opt_details,
            "attention": att_details,
            "fact": fact_details,
            "price_boost": price_boost_details,
            "confluence": {"bonus": confluence, "high_count": high_count},
            "noise": {"penalty": noise},
            "formula": (
                f"{SCORE_WEIGHTS['options']}Ã—{opt_score} + "
                f"{SCORE_WEIGHTS['attention']}Ã—{att_score} + "
                f"{SCORE_WEIGHTS['fact']}Ã—{fact_score} + "
                f"price_boost:{price_boost} + "
                f"confluence:{confluence} - noise:{noise} = {psi}"
            ),
        }
        
        result = {
            "ticker": self.ticker,
            "timestamp": datetime.utcnow().isoformat(),
            "options_score": opt_score,
            "attention_score": att_score,
            "fact_score": fact_score,
            "confluence_bonus": confluence,
            "noise_penalty": noise,
            "psi_total": psi,
            "level": level,
            "details": self.details,
        }
        
        # DB ì €ì¥
        save_psi_score(
            ticker=self.ticker,
            timestamp=result["timestamp"],
            options_score=opt_score,
            attention_score=att_score,
            fact_score=fact_score,
            confluence_bonus=confluence,
            noise_penalty=noise,
            psi_total=psi,
            level=level,
            details=self.details,
        )
        
        return result
    
    # =========================================================
    # 1. Options Anomaly Score (0~10)
    # =========================================================
    def _calc_options_score(self, data: Dict) -> Tuple[float, Dict]:
        """ì˜µì…˜ ì´ìƒ ì ìˆ˜ ê³„ì‚°"""
        score = 0
        details = {"factors": [], "raw": data}
        
        if not data:
            return 0, {"factors": ["ì˜µì…˜ ë°ì´í„° ì—†ìŒ"], "raw": {}}
        
        # OTM ê±°ë˜ëŸ‰ ê¸‰ì¦
        otm_ratio = data.get("otm_call_volume_ratio", 0)
        if otm_ratio >= 5:
            score += OPTIONS_SCORING["otm_volume_5x"]
            details["factors"].append(f"OTM ì½œ ê±°ë˜ëŸ‰ {otm_ratio:.1f}ë°° â†’ +{OPTIONS_SCORING['otm_volume_5x']}")
        elif otm_ratio >= 3:
            score += OPTIONS_SCORING["otm_volume_3x"]
            details["factors"].append(f"OTM ì½œ ê±°ë˜ëŸ‰ {otm_ratio:.1f}ë°° â†’ +{OPTIONS_SCORING['otm_volume_3x']}")
        
        # ë‹¨ê¸°ë§Œê¸° ì§‘ì¤‘
        short_pct = data.get("short_expiry_pct", 0)
        if short_pct >= 0.6:
            score += OPTIONS_SCORING["short_expiry_60pct"]
            details["factors"].append(f"ë‹¨ê¸°ë§Œê¸° ë¹„ì¤‘ {short_pct:.0%} â†’ +{OPTIONS_SCORING['short_expiry_60pct']}")
        
        # OI ê¸‰ë³€
        oi_change = data.get("oi_change_pct", 0)
        if abs(oi_change) >= 50:
            score += OPTIONS_SCORING["oi_change_50pct"]
            details["factors"].append(f"OI ë³€í™” {oi_change:+.0f}% â†’ +{OPTIONS_SCORING['oi_change_50pct']}")
        
        # IV Skew
        iv_skew_sigma = data.get("iv_skew_sigma", 0)
        if abs(iv_skew_sigma) >= 2:
            score += OPTIONS_SCORING["iv_skew_2sigma"]
            details["factors"].append(f"IV Skew {iv_skew_sigma:.1f}Ïƒ â†’ +{OPTIONS_SCORING['iv_skew_2sigma']}")
        
        # ëŒ€ëŸ‰ ê±°ë˜
        large_trades = data.get("large_trade_count", 0)
        if large_trades > 0:
            score += OPTIONS_SCORING["large_trade_100k"]
            details["factors"].append(f"ëŒ€ëŸ‰ê±°ë˜ {large_trades}ê±´ â†’ +{OPTIONS_SCORING['large_trade_100k']}")
        
        # Put/Call ë¹„ìœ¨ ì´ìƒ
        pc_ratio = data.get("pc_ratio", 1.0)
        if pc_ratio < 0.5 or pc_ratio > 2.0:
            score += 1
            details["factors"].append(f"P/C ë¹„ìœ¨ ì´ìƒ: {pc_ratio:.2f} â†’ +1")
        
        score = min(10, score)
        return score, details
    
    # =========================================================
    # 2. Attention Acceleration Score (0~10)
    # =========================================================
    def _calc_attention_score(self, social_data: Dict, news_data: List[Dict]) -> Tuple[float, Dict]:
        """ê´€ì‹¬ë„ ê°€ì†ë„ ì ìˆ˜ ê³„ì‚°"""
        score = 0
        details = {"factors": [], "raw_social": social_data}
        
        # ì†Œì…œ ì–¸ê¸‰ ê°€ì†ë„
        current_mentions = social_data.get("current_mentions", 0)
        previous_mentions = social_data.get("previous_mentions", 0)
        
        if previous_mentions > 0 and current_mentions > 0:
            accel = ((current_mentions - previous_mentions) / previous_mentions) * 100
            if accel >= 300:
                score += ATTENTION_SCORING["mention_accel_300pct"]
                details["factors"].append(f"ì–¸ê¸‰ ê°€ì†ë„ {accel:.0f}% â†’ +{ATTENTION_SCORING['mention_accel_300pct']}")
            elif accel >= 100:
                score += ATTENTION_SCORING["mention_accel_100pct"]
                details["factors"].append(f"ì–¸ê¸‰ ê°€ì†ë„ {accel:.0f}% â†’ +{ATTENTION_SCORING['mention_accel_100pct']}")
        
        # í˜„ì¥ì„± í‚¤ì›Œë“œ ê°ì§€
        breaking_found = False
        for article in news_data:
            text = (article.get('title', '') + ' ' + article.get('summary', '')).lower()
            if any(kw.lower() in text for kw in BREAKING_KEYWORDS):
                breaking_found = True
                break
        
        if breaking_found or social_data.get("breaking_keyword_found", False):
            score += ATTENTION_SCORING["breaking_keywords"]
            details["factors"].append(f"í˜„ì¥ì„± í‚¤ì›Œë“œ ê°ì§€ â†’ +{ATTENTION_SCORING['breaking_keywords']}")
        
        # Google Trends ìŠ¤íŒŒì´í¬
        trends_ratio = social_data.get("google_trends_ratio", 0)
        if trends_ratio >= 2:
            score += ATTENTION_SCORING["google_trends_2x"]
            details["factors"].append(f"Google Trends {trends_ratio:.1f}ë°° â†’ +{ATTENTION_SCORING['google_trends_2x']}")
        
        # ë‹¤ì¤‘ í”Œë«í¼ ë™ì‹œ ê¸‰ì¦
        platforms_active = social_data.get("platforms_active", [])
        if len(platforms_active) >= 2:
            score += ATTENTION_SCORING["multi_platform"]
            details["factors"].append(f"ë‹¤ì¤‘ í”Œë«í¼ ë™ì‹œ: {', '.join(platforms_active)} â†’ +{ATTENTION_SCORING['multi_platform']}")
        
        # ë‰´ìŠ¤ ë³¼ë¥¨ ìì²´ë„ ê°€ì†ë„ ë°˜ì˜
        if len(news_data) >= 10:
            score += 1
            details["factors"].append(f"ë‰´ìŠ¤ ë³¼ë¥¨ {len(news_data)}ê±´ â†’ +1")
        
        score = min(10, score)
        return score, details
    
    # =========================================================
    # 3. Disclosure/Fact Score (0~10)
    # =========================================================
    def _calc_fact_score(self, news_data: List[Dict]) -> Tuple[float, Dict]:
        """ê³µì‹œ/íŒ©íŠ¸ ì ìˆ˜ ê³„ì‚°"""
        score = 0
        details = {"factors": [], "filings": [], "news_count": len(news_data)}
        
        has_8k = False
        has_other_filing = False
        has_regulatory = False
        has_earnings = False
        sources_count = set()
        
        for article in news_data:
            source_type = article.get('source_type', '')
            source = article.get('source', '')
            title = article.get('title', '').lower()
            
            sources_count.add(source)
            
            # SEC Filing ê°ì§€
            if source_type == 'filing' or 'sec' in source.lower():
                if '8-k' in title or '8k' in title:
                    has_8k = True
                    details["filings"].append(article.get('title', ''))
                else:
                    has_other_filing = True
            
            # ê·œì œê¸°ê´€ ë°œí‘œ
            regulatory_terms = ['bis', 'fda', 'ftc', 'doj', 'sec ', 'settlement',
                              'export control', 'entity list', 'approved', 'cleared']
            if any(term in title for term in regulatory_terms):
                has_regulatory = True
            
            # ì‹¤ì  ê´€ë ¨
            earnings_terms = ['earnings', 'eps', 'revenue', 'guidance', 'quarter',
                            'fiscal', 'q1', 'q2', 'q3', 'q4', 'beat', 'miss']
            if any(term in title for term in earnings_terms):
                has_earnings = True
        
        # ì ìˆ˜ ë¶€ì—¬
        if has_8k:
            score += FACT_SCORING["sec_8k"]
            details["factors"].append(f"SEC 8-K Filing ê°ì§€ â†’ +{FACT_SCORING['sec_8k']}")
        elif has_other_filing:
            score += FACT_SCORING["sec_other"]
            details["factors"].append(f"SEC Filing ê°ì§€ â†’ +{FACT_SCORING['sec_other']}")
        
        if has_regulatory:
            score += FACT_SCORING["regulatory"]
            details["factors"].append(f"ê·œì œê¸°ê´€ ë°œí‘œ ê°ì§€ â†’ +{FACT_SCORING['regulatory']}")
        
        if has_earnings:
            score += FACT_SCORING["earnings_window"]
            details["factors"].append(f"ì‹¤ì  ê´€ë ¨ ë‰´ìŠ¤ ê°ì§€ â†’ +{FACT_SCORING['earnings_window']}")
        
        # ë‹¤ì¤‘ ì¶œì²˜ í™•ì¸
        if len(sources_count) >= 3:
            score += FACT_SCORING["multi_source"]
            details["factors"].append(f"ë‹¤ì¤‘ ì¶œì²˜ {len(sources_count)}ê°œ í™•ì¸ â†’ +{FACT_SCORING['multi_source']}")
        
        score = min(10, score)
        return score, details
    
    # =========================================================
    # ë³´ì¡° ê³„ì‚°
    # =========================================================
    def _calc_price_boost(self, price_data: Dict) -> Tuple[float, Dict]:
        """
        ê°€ê²© ì¶©ê²© ë¶€ìŠ¤íŠ¸: í° ê°€ê²© ë³€ë™ ìì²´ê°€ ì´ìƒ ì‹ í˜¸
        Â±2% â†’ +1.0, Â±5% â†’ +2.0, Â±8% â†’ +3.0, Â±10%+ â†’ +4.0
        ê±°ë˜ëŸ‰ 3x ì´ìƒ ì‹œ ì¶”ê°€ +0.5
        """
        boost = 0.0
        details = {"factors": []}
        
        if not price_data:
            return 0.0, details
        
        # ê°€ê²© ë³€ë™ë¥ 
        change_pct = abs(price_data.get("change_pct", 0))
        if change_pct >= 10:
            boost += 4.0
            details["factors"].append(f"ê°€ê²© ë³€ë™ {price_data.get('change_pct', 0):+.1f}% â†’ +4.0")
        elif change_pct >= 8:
            boost += 3.0
            details["factors"].append(f"ê°€ê²© ë³€ë™ {price_data.get('change_pct', 0):+.1f}% â†’ +3.0")
        elif change_pct >= 5:
            boost += 2.0
            details["factors"].append(f"ê°€ê²© ë³€ë™ {price_data.get('change_pct', 0):+.1f}% â†’ +2.0")
        elif change_pct >= 2:
            boost += 1.0
            details["factors"].append(f"ê°€ê²© ë³€ë™ {price_data.get('change_pct', 0):+.1f}% â†’ +1.0")
        
        # ê±°ë˜ëŸ‰ ê¸‰ì¦
        vol_ratio = price_data.get("volume_ratio", 1.0)
        if vol_ratio >= 3:
            boost += 0.5
            details["factors"].append(f"ê±°ë˜ëŸ‰ {vol_ratio:.1f}x í‰ê·  â†’ +0.5")
        
        return min(4.5, boost), details
    
    def _calc_noise_penalty(self, attention_score: float, fact_score: float) -> float:
        """Noise íŒ¨ë„í‹°: ê´€ì‹¬ë„ë§Œ ë†’ê³  íŒ©íŠ¸ê°€ ì—†ìœ¼ë©´ ì°¨ê°"""
        if attention_score >= 5 and fact_score <= 2:
            return min(NOISE_PENALTY_MAX, (attention_score - fact_score) * 0.3)
        return 0
    
    def _get_level(self, psi: float) -> str:
        """PSI ë“±ê¸‰ íŒì •"""
        for level, (low, high) in PSI_LEVELS.items():
            if low <= psi < high:
                return level
        return "critical" if psi >= 7 else "normal"


# ============================================================
# Flash Reason Engine (ê°„ì†Œí™” ë²„ì „)
# ============================================================

class FlashReasonEngine:
    """60ì´ˆ ì›ì¸ ê·œëª… ì—”ì§„"""
    
    def __init__(self, ticker: str):
        self.ticker = ticker
        self.watch = WATCHMAP.get(ticker)
    
    def analyze(self, news_data: List[Dict], price_data: Dict = None,
                options_data: Dict = None) -> Dict:
        """
        ì›ì¸ í›„ë³´ Top-3 ìƒì„± + Noise/Fracture/Catalyst ë¶„ë¥˜
        """
        # 1. ë‰´ìŠ¤ë¥¼ ì‹œê°„ìˆœ ì •ë ¬ + ê´€ë ¨ë„ ìŠ¤ì½”ì–´ë§
        scored_news = self._score_and_rank_news(news_data)
        
        # 2. Top-3 í›„ë³´ ì¶”ì¶œ
        top3 = scored_news[:3]
        
        reason_candidates = []
        for i, item in enumerate(top3):
            reason_candidates.append({
                "rank": i + 1,
                "title": item["title"],
                "summary": item.get("summary", "")[:200],
                "source_url": item.get("url", ""),
                "source": item.get("source", ""),
                "source_type": item.get("source_type", "news"),
                "confidence": item.get("relevance_score", 0.5),
                "event_type": self._classify_event_type(item),
                "sentiment": item.get("sentiment", "neutral"),
                "timestamp": item.get("timestamp", ""),
            })
        
        # 3. Noise / Fracture / Catalyst ë¶„ë¥˜
        classification = self._classify_event(reason_candidates, news_data, price_data)
        
        # 4. í”Œë ˆì´ë¶ ê²°ì •
        playbook = self._get_playbook(classification)
        
        return {
            "ticker": self.ticker,
            "timestamp": datetime.utcnow().isoformat(),
            "reason_candidates": reason_candidates,
            "classification": classification,
            "playbook": playbook,
        }
    
    def _score_and_rank_news(self, news_data: List[Dict]) -> List[Dict]:
        """ë‰´ìŠ¤ ê´€ë ¨ë„ ìŠ¤ì½”ì–´ë§ + ë­í‚¹"""
        for article in news_data:
            score = 0
            title = article.get('title', '').lower()
            
            # í‚¤ì›Œë“œ ë§¤ì¹­ ì ìˆ˜
            matched = article.get('keywords_matched', [])
            score += len(matched) * 0.1
            
            # ì†ŒìŠ¤ íƒ€ì… ê°€ì¤‘ì¹˜
            if article.get('source_type') == 'filing':
                score += 0.3
            elif article.get('source') in ['finnhub', 'sec_edgar']:
                score += 0.2
            
            # í˜„ì¥ì„± í‚¤ì›Œë“œ
            if any(kw.lower() in title for kw in BREAKING_KEYWORDS):
                score += 0.2
            
            # ì‹œê°„ ê°€ì¤‘ì¹˜ (ìµœì‹ ì¼ìˆ˜ë¡ ë†’ìŒ)
            try:
                pub_time = datetime.fromisoformat(article.get('timestamp', ''))
                hours_ago = (datetime.utcnow() - pub_time).total_seconds() / 3600
                if hours_ago < 1:
                    score += 0.3
                elif hours_ago < 6:
                    score += 0.2
                elif hours_ago < 24:
                    score += 0.1
            except:
                pass
            
            article['relevance_score'] = min(1.0, round(score, 2))
        
        # ê´€ë ¨ë„ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        return sorted(news_data, key=lambda x: x.get('relevance_score', 0), reverse=True)
    
    def _classify_event_type(self, article: Dict) -> str:
        """ì‚¬ê±´ ìœ í˜• ë¶„ë¥˜"""
        title = article.get('title', '').lower()
        
        type_keywords = {
            "earnings": ['earnings', 'eps', 'revenue', 'quarter', 'fiscal', 'guidance'],
            "regulatory": ['bis', 'fda', 'ftc', 'sec', 'settlement', 'export', 'sanction', 'penalty'],
            "supply_chain": ['tsmc', 'samsung', 'foundry', 'fab', 'capex', 'equipment order'],
            "analyst": ['upgrade', 'downgrade', 'target', 'rating', 'overweight', 'analyst'],
            "ma": ['acquisition', 'merger', 'buyout', 'deal', 'partnership'],
            "sector": ['semiconductor', 'chip', 'sector', 'etf', 'industry'],
            "macro": ['fed', 'fomc', 'inflation', 'tariff', 'trade war'],
        }
        
        for event_type, keywords in type_keywords.items():
            if any(kw in title for kw in keywords):
                return event_type
        
        return "other"
    
    def _classify_event(self, candidates: List[Dict], all_news: List[Dict],
                        price_data: Dict = None) -> Dict:
        """Noise / Fracture / Catalyst íŒì • â€” ê°€ê²© ë°©í–¥ + íŒ¨í„´ ì¸ì‹"""
        if not candidates:
            return {"type": "Unknown", "confidence": 0, "reasoning": "ë°ì´í„° ë¶€ì¡±"}
        
        # íŒ©íŠ¸ ê·¼ê±° ê°•ë„ í™•ì¸
        fact_sources = sum(1 for c in candidates 
                         if c.get('source_type') in ['filing', 'regulatory'])
        
        # ì„¼í‹°ë©˜íŠ¸ ë°©í–¥
        sentiments = [c.get('sentiment', 'neutral') for c in candidates]
        positive_count = sentiments.count('positive')
        negative_count = sentiments.count('negative')
        
        # í‚¤ì›Œë“œ ì²´í¬
        negative_found = False
        positive_found = False
        all_text = ""
        for c in candidates:
            text = (c.get('title', '') + ' ' + c.get('summary', '')).lower()
            all_text += text + " "
            if any(kw.lower() in text for kw in NEGATIVE_KEYWORDS):
                negative_found = True
            if any(kw.lower() in text for kw in POSITIVE_KEYWORDS):
                positive_found = True
        
        # â”€â”€ ê°€ê²© ë°©í–¥ ì‹ í˜¸ â”€â”€
        price_direction = 0  # -1=í•˜ë½, 0=ì¤‘ë¦½, 1=ìƒìŠ¹
        price_change = 0
        if price_data:
            price_change = price_data.get("change_pct", 0)
            if price_change <= -2:
                price_direction = -1
            elif price_change >= 2:
                price_direction = 1
        
        # â”€â”€ íŒ¨í„´ ì¸ì‹: Beat but Guide Down â”€â”€
        beat_guide_down = False
        guide_down_terms = ['guidance below', 'guide down', 'lowered guidance',
                           'cut guidance', 'reduced outlook', 'below expectations',
                           'disappointing guidance', 'weak guidance', 'outlook miss',
                           'declines after', 'falls despite', 'drops despite',
                           'despite beat', 'despite strong']
        beat_terms = ['beat', 'topped', 'exceeded', 'surpassed', 'above estimate']
        
        has_beat = any(t in all_text for t in beat_terms)
        has_guide_down = any(t in all_text for t in guide_down_terms)
        
        # ì‹¤ì  beat + í•˜ë½ = beat but guide down íŒ¨í„´
        if has_beat and price_direction == -1:
            beat_guide_down = True
        if has_guide_down:
            beat_guide_down = True
        
        # â”€â”€ íŒì • ë¡œì§ (ê°€ê²© ë°©í–¥ ìš°ì„ ) â”€â”€
        
        # 1. Beat but Guide Down â†’ Fracture (ì‹¤ì  ì¢‹ì•„ë„ ê°€ì´ë˜ìŠ¤ê°€ ë‚˜ì˜ë©´ í•˜ë½)
        if beat_guide_down:
            return {
                "type": "Fracture",
                "confidence": 0.9,
                "reasoning": "ì‹¤ì  Beatì—ë„ ê°€ì´ë˜ìŠ¤ í•˜í–¥/ì£¼ê°€ í•˜ë½ â†’ Fracture"
            }
        
        # 2. ê°•í•œ í•˜ë½ + ë‰´ìŠ¤ ìˆìŒ â†’ Fracture
        if price_direction == -1 and (fact_sources >= 1 or len(all_news) >= 3):
            conf = 0.85 if fact_sources >= 1 else 0.7
            return {
                "type": "Fracture",
                "confidence": conf,
                "reasoning": f"ì£¼ê°€ {price_change:+.1f}% í•˜ë½ + ë‰´ìŠ¤ {len(all_news)}ê±´ â†’ Fracture"
            }
        
        # 3. ê°•í•œ ìƒìŠ¹ + íŒ©íŠ¸ ìˆìŒ â†’ Catalyst
        if price_direction == 1 and (fact_sources >= 1 or positive_found):
            conf = 0.85 if fact_sources >= 1 else 0.7
            return {
                "type": "Catalyst",
                "confidence": conf,
                "reasoning": f"ì£¼ê°€ {price_change:+.1f}% ìƒìŠ¹ + íŒ©íŠ¸/ê¸ì • í‚¤ì›Œë“œ â†’ Catalyst"
            }
        
        # 4. íŒ©íŠ¸ ì†ŒìŠ¤ + ë¶€ì • í‚¤ì›Œë“œ â†’ Fracture
        if fact_sources >= 1 and negative_found and not positive_found:
            return {
                "type": "Fracture",
                "confidence": 0.8,
                "reasoning": f"íŒ©íŠ¸ ì†ŒìŠ¤ {fact_sources}ê±´ + ë¶€ì • í‚¤ì›Œë“œ â†’ Fracture"
            }
        
        # 5. íŒ©íŠ¸ ì†ŒìŠ¤ + ê¸ì • í‚¤ì›Œë“œ â†’ Catalyst
        if fact_sources >= 1 and positive_found:
            return {
                "type": "Catalyst",
                "confidence": 0.85,
                "reasoning": f"íŒ©íŠ¸ ì†ŒìŠ¤ {fact_sources}ê±´ + ê¸ì • í‚¤ì›Œë“œ â†’ Catalyst"
            }
        
        # 6. ë‰´ìŠ¤ ë³¼ë¥¨ + ì„¼í‹°ë©˜íŠ¸ ë°©í–¥
        if positive_count > negative_count and len(all_news) >= 5:
            return {
                "type": "Catalyst",
                "confidence": 0.7,
                "reasoning": f"ê¸ì • ë‰´ìŠ¤ {positive_count} > ë¶€ì • {negative_count} + ë‰´ìŠ¤ ë³¼ë¥¨ â†’ Catalyst"
            }
        elif negative_count > positive_count:
            return {
                "type": "Fracture",
                "confidence": 0.65,
                "reasoning": f"ë¶€ì • ë‰´ìŠ¤ {negative_count} > ê¸ì • {positive_count} â†’ Fracture"
            }
        
        return {
            "type": "Noise",
            "confidence": 0.5,
            "reasoning": "íŒ©íŠ¸ ê·¼ê±° ì•½í•¨ + ë°©í–¥ì„± ë¶ˆë¶„ëª… â†’ Noise"
        }
    
    def _get_playbook(self, classification: Dict) -> Dict:
        """ë¶„ë¥˜ì— ë”°ë¥¸ í”Œë ˆì´ë¶"""
        ctype = classification.get("type", "Unknown")
        
        playbooks = {
            "Noise": {
                "id": "PB-NOISE-01",
                "actions": [
                    "ì²´í¬ë¦¬ìŠ¤íŠ¸: íŒ©íŠ¸ ê·¼ê±° ì¬í™•ì¸",
                    "ì¬í‰ê°€ íƒ€ì´ë¨¸: 15ë¶„ í›„",
                    "ì¶”ê°€ ì†ŒìŠ¤ í™•ì¸ í•„ìš”",
                ],
                "reevaluation": "15min"
            },
            "Fracture": {
                "id": "PB-FRACTURE-01",
                "actions": [
                    "ë¦¬ìŠ¤í¬ ìƒí–¥: ì¦‰ì‹œ í¬ì§€ì…˜ ì¬í‰ê°€",
                    "ì†ì ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸ í™•ì¸",
                    "ê´€ë ¨ ì¢…ëª© ì˜í–¥ í™•ì¸",
                    "ì¬í‰ê°€ íƒ€ì´ë¨¸: ì¢…ê°€ ê¸°ì¤€",
                ],
                "reevaluation": "close"
            },
            "Catalyst": {
                "id": "PB-CATALYST-01",
                "actions": [
                    "ì¶”ì  ê°•í™”: 15ë¶„ ê°„ê²© ëª¨ë‹ˆí„°ë§",
                    "ê´€ë ¨ ì¢…ëª© ë™í–¥ í™•ì¸",
                    "ì¬í‰ê°€ ì‹œì : ì¢…ê°€ ê¸°ì¤€",
                    "ì„œì‚¬ ì „í™˜ ì—¬ë¶€ ì¶”ì ",
                ],
                "reevaluation": "close"
            },
        }
        
        return playbooks.get(ctype, {
            "id": "PB-UNKNOWN-01",
            "actions": ["ìˆ˜ë™ í™•ì¸ í•„ìš”"],
            "reevaluation": "30min"
        })


# ============================================================
# í…ŒìŠ¤íŠ¸
# ============================================================
if __name__ == "__main__":
    # AMAT ì‹¤ì œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    engine = PreSignalEngine("AMAT")
    
    # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
    options_data = {
        "otm_call_volume_ratio": 4.2,
        "short_expiry_pct": 0.65,
        "oi_change_pct": 55,
        "iv_skew_sigma": 2.3,
        "large_trade_count": 3,
        "pc_ratio": 0.45,
    }
    
    social_data = {
        "current_mentions": 340,
        "previous_mentions": 100,
        "breaking_keyword_found": True,
        "google_trends_ratio": 2.5,
        "platforms_active": ["reddit", "stocktwits"],
    }
    
    news_data = [
        {"title": "Applied Materials Q1 earnings beat estimates", 
         "source_type": "news", "source": "finnhub", "sentiment": "positive",
         "keywords_matched": ["AMAT", "earnings"], "timestamp": "2026-02-12T21:00:00",
         "url": "https://example.com/1", "summary": "EPS $2.38 vs $2.25 expected"},
        {"title": "[SEC 8-K] Applied Materials Q1 2026 Results",
         "source_type": "filing", "source": "sec_edgar", "sentiment": "neutral",
         "keywords_matched": ["AMAT"], "timestamp": "2026-02-12T21:30:00",
         "url": "https://example.com/2", "summary": ""},
        {"title": "BIS settlement: Applied Materials pays $252M penalty",
         "source_type": "news", "source": "google_news", "sentiment": "negative",
         "keywords_matched": ["AMAT", "BIS", "export control"],
         "timestamp": "2026-02-11T21:00:00", "url": "https://example.com/3",
         "summary": "Settlement resolves export violations"},
        {"title": "Applied Materials guidance above consensus, shares surge",
         "source_type": "news", "source": "finnhub", "sentiment": "positive",
         "keywords_matched": ["AMAT", "guidance"], "timestamp": "2026-02-13T10:00:00",
         "url": "https://example.com/4", "summary": "Q2 guidance $7.65B vs $7.02B expected"},
        {"title": "KeyBanc raises AMAT target to $450, sees 37% upside",
         "source_type": "news", "source": "google_news", "sentiment": "positive",
         "keywords_matched": ["AMAT"], "timestamp": "2026-02-13T12:00:00",
         "url": "https://example.com/5", "summary": ""},
    ]
    
    # PSI ê³„ì‚°
    from storage.database import init_db
    init_db()
    
    result = engine.calculate(
        options_data=options_data,
        social_data=social_data,
        news_data=news_data,
    )
    
    print("\n" + "=" * 60)
    print(f"ğŸ“¡ PRE-SIGNAL INDEX: {result['ticker']}")
    print("=" * 60)
    print(f"  Options Anomaly:     {result['options_score']}/10")
    print(f"  Attention Accel:     {result['attention_score']}/10")
    print(f"  Disclosure/Fact:     {result['fact_score']}/10")
    print(f"  Confluence Bonus:    +{result['confluence_bonus']}")
    print(f"  Noise Penalty:       -{result['noise_penalty']}")
    print(f"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print(f"  PSI Total:           {result['psi_total']}/10")
    print(f"  Level:               {result['level'].upper()}")
    
    # Flash Reason
    flash = FlashReasonEngine("AMAT")
    reason_result = flash.analyze(news_data)
    
    print(f"\nğŸ” FLASH REASON:")
    print(f"  Classification: {reason_result['classification']['type']}")
    print(f"  Confidence: {reason_result['classification']['confidence']:.0%}")
    print(f"  Playbook: {reason_result['playbook']['id']}")
    print(f"\n  Top-3 ì›ì¸ í›„ë³´:")
    for c in reason_result['reason_candidates']:
        print(f"    #{c['rank']} [{c['event_type']}] {c['title'][:60]}")
        print(f"       ì‹ ë¢°ë„: {c['confidence']:.0%} | {c['sentiment']}")
