"""
Stock Sentinel â€” AI ìš”ì•½ ì—”ì§„ v2
í™˜ê° ë°©ì§€: ìˆ˜ì§‘ëœ ë‰´ìŠ¤ì— ì–¸ê¸‰ëœ íŒ©íŠ¸ë§Œ ì‚¬ìš©, ì¶”ì¸¡/ì¼ë°˜ë¡  ê¸ˆì§€
"""
import os
import json
import requests
from typing import Dict, List, Optional
from urllib.parse import urlparse

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY", "")
MODEL = "gpt-4.1-mini"


def _is_valid_article_url(url: str) -> bool:
    if not url:
        return False
    bad = ["news.google.com/rss", "finnhub.io/api"]
    if any(p in url for p in bad):
        return False
    try:
        path = urlparse(url).path.strip("/")
        return bool(path) and len(path) >= 3
    except:
        return False


def summarize_event(ticker: str, news_data: List[Dict], price_data: Dict = None) -> Dict:
    """
    ë‰´ìŠ¤ + ê°€ê²© â†’ í•œêµ­ì–´ ìš”ì•½.
    í•µì‹¬ ì›ì¹™: ìˆ˜ì§‘ëœ ë‰´ìŠ¤ì— ìˆëŠ” ì •ë³´ë§Œ ì‚¬ìš©. ì¶”ì¸¡/ì¼ë°˜ë¡  ì ˆëŒ€ ê¸ˆì§€.
    """
    if not OPENAI_API_KEY:
        return _fallback_summary(ticker, news_data, price_data)

    # ë‰´ìŠ¤ í…ìŠ¤íŠ¸ (ìµœëŒ€ 10ê±´)
    news_text = ""
    sources = []
    for i, article in enumerate(news_data[:10]):
        title = article.get("title", "").strip()
        summary = article.get("summary", "").strip()[:200]
        source = article.get("source", "")
        url = article.get("url", "")
        sentiment = article.get("sentiment", "")

        news_text += f"[{i+1}] {title}\n"
        if summary:
            news_text += f"    {summary}\n"
        news_text += f"    ì¶œì²˜: {source} | ì„¼í‹°ë©˜íŠ¸: {sentiment}\n\n"

        if url and _is_valid_article_url(url):
            sources.append(url)

    # ê°€ê²© ì •ë³´
    price_info = ""
    if price_data:
        change = price_data.get("change_pct", 0)
        vol = price_data.get("volume_ratio", 1.0)
        latest = price_data.get("latest", {})
        close = latest.get("close", 0) if latest else 0
        direction = "ìƒìŠ¹" if change > 0 else "í•˜ë½" if change < 0 else "ë³´í•©"
        price_info = f"í˜„ì¬ê°€: ${close:.2f} | ë³€ë™: {change:+.1f}% ({direction}) | ê±°ë˜ëŸ‰: í‰ê·  ëŒ€ë¹„ {vol:.1f}ë°°"

    # â•â•â• í™˜ê° ë°©ì§€ í”„ë¡¬í”„íŠ¸ â•â•â•
    prompt = f"""ì•„ë˜ {ticker} ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ JSONìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.

## ì ˆëŒ€ ê·œì¹™
1. headlineê³¼ detailì€ ë°˜ë“œì‹œ ì•„ë˜ ë‰´ìŠ¤ ëª©ë¡ì— ë‚˜ì˜¨ ì •ë³´ë§Œ ì‚¬ìš©í•  ê²ƒ
2. ë‰´ìŠ¤ì— ì—†ëŠ” ì¶”ì¸¡, ì „ë§, ì¼ë°˜ë¡  ì ˆëŒ€ ê¸ˆì§€ (ì˜ˆ: "AI ìˆ˜ìš” í™•ëŒ€", "ì‹œì¥ ì„±ì¥ ì „ë§" ë“± ì‚½ì… ê¸ˆì§€)
3. ì–´ë–¤ ë‰´ìŠ¤ê°€ ê°€ì¥ ì§ì ‘ì ì¸ ì›ì¸ì¸ì§€ ë²ˆí˜¸ë¡œ ëª…ì‹œí•  ê²ƒ
4. ë‰´ìŠ¤ì—ì„œ êµ¬ì²´ì  ì›ì¸ì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ headlineì„ "ì›ì¸ ë¯¸í™•ì¸ â€” ì¶”ê°€ í™•ì¸ í•„ìš”"ë¡œ ì‘ì„±

## ê°€ê²© ë°ì´í„°
{price_info or "ì—†ìŒ"}

## ìµœê·¼ ë‰´ìŠ¤
{news_text}

## JSON í˜•ì‹ (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ):
{{
  "headline": "ë‰´ìŠ¤ì—ì„œ í™•ì¸ëœ í•µì‹¬ ì›ì¸ í•œ ì¤„ (í•œêµ­ì–´, 25ì ì´ë‚´)",
  "detail": "í•´ë‹¹ ë‰´ìŠ¤ì˜ êµ¬ì²´ì  ë‚´ìš© 1ë¬¸ì¥ (í•œêµ­ì–´, ë‰´ìŠ¤ ì›ë¬¸ ê¸°ë°˜ë§Œ)",
  "classification": "Catalyst / Fracture / Noise",
  "confidence": 0.0~1.0,
  "event_type": "earnings/guidance/partnership/ma/regulatory/analyst/sector/macro/other",
  "primary_source_index": ê°€ì¥ í•µì‹¬ ë‰´ìŠ¤ ë²ˆí˜¸ (ì •ìˆ˜)
}}"""

    try:
        resp = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {OPENAI_API_KEY}",
                "Content-Type": "application/json",
            },
            json={
                "model": MODEL,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.1,  # ë” ë‚®ì¶°ì„œ ì°½ì‘ ì–µì œ
                "max_tokens": 250,
            },
            timeout=15,
        )

        if resp.status_code != 200:
            print(f"  âš ï¸ OpenAI API ì˜¤ë¥˜ {resp.status_code}: {resp.text[:200]}")
            return _fallback_summary(ticker, news_data, price_data)

        content = resp.json()["choices"][0]["message"]["content"].strip()
        if content.startswith("```"):
            content = content.split("\n", 1)[1].rsplit("```", 1)[0]

        result = json.loads(content)
        result["source_count"] = len(news_data)
        result["key_source"] = sources[0] if sources else ""
        result["ai_generated"] = True

        # primary_source_indexë¡œ key_source ë³´ì •
        psi = result.get("primary_source_index")
        if isinstance(psi, int) and 1 <= psi <= len(news_data):
            candidate_url = news_data[psi - 1].get("url", "")
            if _is_valid_article_url(candidate_url):
                result["key_source"] = candidate_url

        print(f"  ğŸ¤– AI ìš”ì•½: {result.get('headline', '?')}")
        return result

    except json.JSONDecodeError as e:
        print(f"  âš ï¸ AI JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return _fallback_summary(ticker, news_data, price_data)
    except Exception as e:
        print(f"  âš ï¸ OpenAI ìš”ì•½ ì‹¤íŒ¨: {e}")
        return _fallback_summary(ticker, news_data, price_data)


def _fallback_summary(ticker: str, news_data: List[Dict], price_data: Dict = None) -> Dict:
    """AI ì—†ì´ ê·œì¹™ ê¸°ë°˜ í´ë°± â€” ë‰´ìŠ¤ ì œëª© ê·¸ëŒ€ë¡œ ì‚¬ìš©"""
    headline = ""
    event_type = "other"
    classification = "Noise"

    if news_data:
        top = news_data[0]
        headline = top.get("title", "")[:45]

        title_lower = headline.lower()
        if any(w in title_lower for w in ["earnings", "eps", "revenue", "quarter"]):
            event_type = "earnings"
        elif any(w in title_lower for w in ["deal", "partner", "contract"]):
            event_type = "partnership"
        elif any(w in title_lower for w in ["upgrade", "downgrade", "target", "rating"]):
            event_type = "analyst"
        elif any(w in title_lower for w in ["bis", "fda", "sec", "sanction", "export"]):
            event_type = "regulatory"

    if price_data:
        change = price_data.get("change_pct", 0)
        if change >= 2:
            classification = "Catalyst"
        elif change <= -2:
            classification = "Fracture"

    return {
        "headline": headline or f"{ticker} ì‹œì¥ ë³€ë™ â€” ì›ì¸ í™•ì¸ í•„ìš”",
        "detail": "",
        "classification": classification,
        "confidence": 0.5,
        "event_type": event_type,
        "source_count": len(news_data),
        "key_source": "",
        "ai_generated": False,
    }
